# Predicting House Prices using Linear Regression, Random Forest, and XGBoost

## ğŸ“š Project Overview
This project aims to predict house prices using three machine learning models: Linear Regression, Random Forest, and XGBoost. The dataset used is sourced from Kaggle's "House Prices - Advanced Regression Techniques" competition.

The main objectives of the project are:
- Perform thorough data preprocessing (handling missing values, outliers, encoding, scaling).
- Train and evaluate three different regression models.
- Apply hyperparameter tuning to optimize model performance.
- Compare models based on metrics like MAE, MSE, RMSE, and RÂ².

## ğŸ“‚ Project Structure
- `Predicting_House_Prices.ipynb` â€” Jupyter Notebook containing the full implementation.
- `train.csv` â€” Training dataset.
- `test.csv` â€” Testing dataset.
- `data_description.txt` â€” Description of each feature in the dataset.
- `Predicting_House_Prices_Report.pdf` â€” Complete project report documenting methodology, results, and conclusions.

## ğŸ“ˆ Algorithms Used
- Linear Regression
- Random Forest Regressor
- XGBoost Regressor

## ğŸ› ï¸ Tools & Libraries
- Python
- Jupyter Notebook (Kaggle environment)
- pandas, numpy, matplotlib, seaborn
- scikit-learn
- XGBoost

## ğŸ“Š Evaluation Metrics
- Mean Absolute Error (MAE)
- Mean Squared Error (MSE)
- Root Mean Squared Error (RMSE)
- R-squared (RÂ²) Score

## ğŸ”¥ Key Results
- XGBoost achieved the highest accuracy among all models.
- Ensemble methods like Random Forest and XGBoost outperformed simple Linear Regression.

## ğŸ”® Future Scope
- Explore LightGBM, CatBoost, and Support Vector Regression (SVR).
- Implement model stacking and advanced hyperparameter tuning (Bayesian Optimization).
- Deploy the model using Streamlit or Flask for real-time predictions.

## ğŸ·ï¸ Dataset Reference
- [House Prices - Advanced Regression Techniques (Kaggle)](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)
